<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>GPU Â· CMBLensing.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/cmblensing.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">CMBLensing.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">CMBLensing.jl</a></li><li><a class="tocitem" href="../01_lense_a_map/">Lensing a flat-sky map</a></li><li><a class="tocitem" href="../02_posterior/">The Lensing Posterior</a></li><li><a class="tocitem" href="../03_joint_MAP_example/">MAP estimation</a></li><li><a class="tocitem" href="../04_from_python/">Calling from Python</a></li><li><a class="tocitem" href="../05_field_basics/">Field Basics</a></li><li class="is-active"><a class="tocitem" href>GPU</a><ul class="internal"><li><a class="tocitem" href="#CuArrays-basics-1"><span>CuArrays basics</span></a></li><li><a class="tocitem" href="#CMBLensing-GPU-basics-1"><span>CMBLensing GPU basics</span></a></li><li><a class="tocitem" href="#Batching-1"><span>Batching</span></a></li><li><a class="tocitem" href="#Gotchas-1"><span>Gotchas</span></a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"></nav><div class="docs-right"><a class="docs-right" href="https://mybinder.org/v2/gh/marius311/CMBLensing.jl/gh-pages?urlpath=lab/tree/06_gpu.ipynb"><img src="https://mybinder.org/badge_logo.svg"/></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="GPU-1"><a class="docs-heading-anchor" href="#GPU-1">GPU</a><a class="docs-heading-anchor-permalink" href="#GPU-1" title="Permalink"></a></h1><p>CMBLensing uses <a href="https://github.com/JuliaGPU/CuArrays.jl">CuArrays</a> for GPU functionality. (Recently CuArrays was merged into CUDA.jl, which CMBLensing doesn&#39;t quite yet support but will in the near future).</p><p>To use CuArrays, you&#39;ll need an Nvidia GPU and a recent version of CUDA. On NERSC, all you need to do is load the modules <code>cudnn/7.6.5</code> and <code>cuda/10.2.89</code> (other versions may work but those have been tested), as well as adding <code>export JULIA_CUDA_USE_BINARYBUILDER=false</code> to your bashrc. </p><p>You could also leave <code>export JULIA_CUDA_USE_BINARYBUILDER=true</code> (the default) and then CuArrays installs CUDA for you. See the <a href="https://juliagpu.gitlab.io/CUDA.jl/installation/overview/">install instructions</a> for more info. </p><h2 id="CuArrays-basics-1"><a class="docs-heading-anchor" href="#CuArrays-basics-1">CuArrays basics</a><a class="docs-heading-anchor-permalink" href="#CuArrays-basics-1" title="Permalink"></a></h2><p>To start, load the packages. Note that due to some Julia intricasies, you must load CuArrays first:</p><pre class="language-julia"><code class="language-julia">using CuArrays, Adapt, CMBLensing, PyPlot</code></pre><p>To check everything loaded correctly:</p><pre class="language-julia"><code class="language-julia">CuArrays.CUDAdrv.device()</code></pre><pre class="language-output"><code class="language-output">CuDevice(0): Tesla V100-SXM2-16GB</code></pre><pre class="language-julia"><code class="language-julia">CuArrays.functional()</code></pre><pre class="language-output"><code class="language-output">true</code></pre><p>CuArrays provides an array type called <code>CuArray</code> which is an array that resides on GPU. You can convert <code>Array</code>s to <code>CuArray</code>s via the <code>adapt</code> function:</p><pre class="language-julia"><code class="language-julia">x_cpu = rand(128,128)
x_gpu = adapt(CuArray, x_cpu)</code></pre><pre class="language-output"><code class="language-output">128Ã—128 CuArray{Float32,2,Nothing}:
 0.988818  0.295359  0.211963   0.983424  â€¦  0.847249   0.820714   0.893246
 0.418397  0.764404  0.141044   0.655638     0.977251   0.0826198  0.198915
 0.709536  0.181498  0.29587    0.737663     0.0273575  0.79535    0.0835606
 â‹®                                        â‹±  â‹®                     
 0.019348  0.117929  0.540368   0.67102      0.205825   0.543327   0.633906
 0.310995  0.347775  0.0373928  0.709054     0.570713   0.199229   0.650354</code></pre><p>Any operations you now to do <code>x_gpu</code> are done on GPU and are super fast (although benchmarking can be <a href="https://juliagpu.gitlab.io/CUDA.jl/development/profiling/">subtle</a>):</p><pre class="language-julia"><code class="language-julia">2 * x_gpu + x_gpu # happened on GPU</code></pre><pre class="language-output"><code class="language-output">128Ã—128 CuArray{Float32,2,Nothing}:
 2.96646   0.886076  0.635888  2.95027  â€¦  2.54175    2.46214   2.67974
 1.25519   2.29321   0.423131  1.96691     2.93175    0.247859  0.596745
 2.12861   0.544494  0.887611  2.21299     0.0820725  2.38605   0.250682
 â‹®                                      â‹±  â‹®                    
 0.058044  0.353788  1.6211    2.01306     0.617475   1.62998   1.90172
 0.932985  1.04332   0.112178  2.12716     1.71214    0.597687  1.95106</code></pre><p>Note also that <code>cu(x)</code> is shorthand for <code>adapt(CuArray{Float32}, x)</code>, and <code>cpu(x)</code> is shorthand for <code>adapt(Array, x)</code> which moves a GPU array back to CPU (generally there&#39;s not many situations where you need to explicitly do this). </p><h2 id="CMBLensing-GPU-basics-1"><a class="docs-heading-anchor" href="#CMBLensing-GPU-basics-1">CMBLensing GPU basics</a><a class="docs-heading-anchor-permalink" href="#CMBLensing-GPU-basics-1" title="Permalink"></a></h2><p>CMBLensing fields can be put on GPU in exactly the same way.</p><pre class="language-julia"><code class="language-julia">f_cpu = FlatMap(rand(128,128))
f_gpu = cu(f_cpu)</code></pre><pre class="language-output"><code class="language-output">16384-element FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, CuArray{Float32,2,Nothing}}:
 0.12150088
 0.04382053
 0.3003088
 â‹®
 0.83403116
 0.5639448</code></pre><p>Everything you can do to a CPU Field object you can do to a GPU one. </p><pre class="language-julia"><code class="language-julia">f_gpu&#39; * (2 * Fourier(f_gpu))</code></pre><pre class="language-output"><code class="language-output">10821.371f0</code></pre><p><code>cu(x)</code> works recursively through most objects, for example through NamedTuples:</p><pre class="language-julia"><code class="language-julia">(x=f_cpu, y=f_cpu) |&gt; typeof</code></pre><pre class="language-output"><code class="language-output">NamedTuple{(:x, :y),Tuple{FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, Array{Float64,2}},FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, Array{Float64,2}}}}</code></pre><pre class="language-julia"><code class="language-julia">cu((x=f_cpu, y=f_cpu)) |&gt; typeof</code></pre><pre class="language-output"><code class="language-output">NamedTuple{(:x, :y),Tuple{FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, CuArray{Float32,2,Nothing}},FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, CuArray{Float32,2,Nothing}}}}</code></pre><p>You can move an entire <code>DataSet</code> to GPU too with <code>cu(ds)</code>, which recursively moves all the fields and operators inside this object to GPU:</p><pre class="language-julia"><code class="language-julia">@unpack ds, Ï• = load_sim(Nside=256, Î¸pix=3, pol=:P);</code></pre><pre class="language-julia"><code class="language-julia">ds.d |&gt; typeof</code></pre><pre class="language-output"><code class="language-output">FlatEBFourier{256Ã—256 map, 3â€² pixels, fourierâˆ‚, Array{Complex{Float32},2}}</code></pre><pre class="language-julia"><code class="language-julia">cu(ds).d |&gt; typeof</code></pre><pre class="language-output"><code class="language-output">FlatEBFourier{256Ã—256 map, 3â€² pixels, fourierâˆ‚, CuArray{Complex{Float32},2,Nothing}}</code></pre><p>Note that on NERSC, the <code>load_sim</code> command above is really slow because the GPU nodes only give you a few CPU cores per GPU (rathre than the 64 cores you get on a CPU compute node). You can also generate the <code>DataSet</code> directly on GPU, which is much faster:</p><pre class="language-julia"><code class="language-julia">@unpack ds, Ï• = load_sim(Nside=256, Î¸pix=3, pol=:P, storage=CuArray);</code></pre><p>Once you have the <code>DataSet</code> object on GPU, all the normal high-level operations work on it, e.g.:</p><pre class="language-julia"><code class="language-julia">fJ,Ï•J = MAP_joint(ds, nsteps=10, progress=true);</code></pre><pre class="language-output"><code class="language-output">[32mMAP_joint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:06[39m
[34m  step:  10[39m
[34m  Ï‡Â²:    131647.67[39m
[34m  Ncg:   3[39m
[34m  Î±:     0.039566778[39m</code></pre><pre class="language-julia"><code class="language-julia">plot([Ï• Ï•J])</code></pre><p><img src="../06_gpu_files/06_gpu_29_0.png" alt="png"/></p><h2 id="Batching-1"><a class="docs-heading-anchor" href="#Batching-1">Batching</a><a class="docs-heading-anchor-permalink" href="#Batching-1" title="Permalink"></a></h2><p>Just moving a <code>DataSet</code> to GPU will give you factors of about 2 - 10 speeds over CPU for <code>Nside</code> of 128 - 1024. You can go even faster by &quot;batching,&quot; which means doing the same operations to multiple fields at once, i.e. in &quot;batches&quot;. The trick is that for the full speedup, this parallelization has to happen on the inner-most-loop so that the GPU basically goes through the data all at once with a single GPU kernel. You do this by putting multiple fields into single &quot;batched fields&quot;. </p><p>Suppose you had 10 fields on GPU that you want to lense:</p><pre class="language-julia"><code class="language-julia">fs = [simulate(ds.Cf) for i=1:10]
Ï•s = [simulate(ds.CÏ•) for i=1:10];</code></pre><p>You could do the following, and it might still be a little faster than doing it sequentially:</p><pre class="language-julia"><code class="language-julia">fÌƒs = [LenseFlow(Ï•)*f for (f,Ï•) in zip(fs,Ï•s)];</code></pre><p>But the <em>really</em> fast way to do it is pack those 10 fields into a batched field (note the indication these are batched in the printed type information):</p><pre class="language-julia"><code class="language-julia">f_batch = batch(fs)</code></pre><pre class="language-output"><code class="language-output">65536(Ã—10)-element FlatEBFourier{256Ã—256(Ã—10) map, 3â€² pixels, fourierâˆ‚, CuArray{Complex{Float32},3,Nothing}}:
         0.0f0 + 0.0f0im
  -3492.4922f0 - 1109.4574f0im
   6461.9375f0 - 907.379f0im
               â‹®
   0.0634754f0 - 0.38553452f0im
 -0.09508268f0 - 0.46648568f0im</code></pre><pre class="language-julia"><code class="language-julia">Ï•_batch = batch(Ï•s)</code></pre><pre class="language-output"><code class="language-output">65536(Ã—10)-element FlatFourier{256Ã—256(Ã—10) map, 3â€² pixels, fourierâˆ‚, CuArray{Complex{Float32},3,Nothing}}:
         -0.0f0 + 0.0f0im
  -0.30419618f0 + 0.045553643f0im
 -0.039095096f0 + 0.035155725f0im
                â‹®
   -8.172244f-8 + 1.6490084f-6im
   -9.995073f-8 + 3.9959605f-8im</code></pre><p>And then run the lensing operation once, which will lense each of the 10 <code>f</code>s by the corresponding <code>Ï•</code>. </p><pre class="language-julia"><code class="language-julia">fÌƒ_batch = LenseFlow(Ï•_batch) * f_batch</code></pre><pre class="language-output"><code class="language-output">65536(Ã—10)-element FlatQUMap{256Ã—256(Ã—10) map, 3â€² pixels, fourierâˆ‚, CuArray{Float32,3,Nothing}}:
 -0.61819124
  1.7315598
  0.0047614807
  â‹®
 -6.1609354
 -6.158243</code></pre><p>For the problem size of <code>Nside=256</code>, doing this batch of 10 lenses is almost no slower than doing a single one. </p><p>You can get the individual fields out of the batched result with <code>batchindex</code>, e.g. the first 2 (out of 10) lensed B fields:</p><pre class="language-julia"><code class="language-julia">plot([batchindex(fÌƒ_batch,1) batchindex(fÌƒ_batch, 2)], which=:Bx)</code></pre><p><img src="../06_gpu_files/06_gpu_42_0.png" alt="png"/></p><p>Normal broadcasting rules apply between batched and non-batched fields, so e.g.:</p><pre class="language-julia"><code class="language-julia">LenseFlow(Ï•) * f_batch</code></pre><pre class="language-output"><code class="language-output">65536(Ã—10)-element FlatQUMap{256Ã—256(Ã—10) map, 3â€² pixels, fourierâˆ‚, CuArray{Float32,3,Nothing}}:
 -0.5668847
 -0.022083389
  1.7046621
  â‹®
 -4.238705
 -5.657242</code></pre><p>works and lenses the 10 different fields in <code>f_batch</code> by the <em>same</em> (non-batched) <code>Ï•</code>.</p><p>Most of CMBLensing works with batched fields just like with normal fields. This includes things like <code>lnP</code>, <code>conjugate_gradient</code> or <code>sample_joint</code>, although <code>MAP_joint</code> and <code>MAP_marg</code> only work with non-batched fields (but will be fixed in the future).</p><h2 id="Gotchas-1"><a class="docs-heading-anchor" href="#Gotchas-1">Gotchas</a><a class="docs-heading-anchor-permalink" href="#Gotchas-1" title="Permalink"></a></h2><p>Not much, hopefully. If something that works on CPU doesn&#39;t work on GPU, please file an Issue.</p><p>One thing to keep in mind is that CPU and GPU use different random number generators, so seeds will not correspond.</p><pre class="language-julia"><code class="language-julia">plot([simulate(cpu(ds.CÏ•),seed=0) simulate(cu(ds.CÏ•),seed=0)])</code></pre><p><img src="../06_gpu_files/06_gpu_50_0.png" alt="png"/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../05_field_basics/">Â« Field Basics</a><a class="docs-footer-nextpage" href="../api/">API Â»</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 16 November 2020 01:03">Monday 16 November 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
