<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>GPU Â· CMBLensing.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/cmblensing.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">CMBLensing.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">CMBLensing.jl</a></li><li><a class="tocitem" href="../01_lense_a_map/">Lensing a flat-sky map</a></li><li><a class="tocitem" href="../02_posterior/">The Lensing Posterior</a></li><li><a class="tocitem" href="../03_joint_MAP_example/">MAP estimation</a></li><li><a class="tocitem" href="../04_from_python/">Calling from Python</a></li><li><a class="tocitem" href="../05_field_basics/">Field Basics</a></li><li class="is-active"><a class="tocitem" href>GPU</a><ul class="internal"><li><a class="tocitem" href="#CUDA-basics-1"><span>CUDA basics</span></a></li><li><a class="tocitem" href="#CMBLensing-GPU-basics-1"><span>CMBLensing GPU basics</span></a></li><li><a class="tocitem" href="#Batching-1"><span>Batching</span></a></li><li><a class="tocitem" href="#Gotchas-1"><span>Gotchas</span></a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"></nav><div class="docs-right"><a class="docs-right" href="https://mybinder.org/v2/gh/marius311/CMBLensing.jl/gh-pages?urlpath=lab/tree/06_gpu.ipynb"><img src="https://mybinder.org/badge_logo.svg"/></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="GPU-1"><a class="docs-heading-anchor" href="#GPU-1">GPU</a><a class="docs-heading-anchor-permalink" href="#GPU-1" title="Permalink"></a></h1><p>CMBLensing uses <a href="https://github.com/JuliaGPU/CUDA.jl">CUDA.jl</a> for GPU functionality. </p><p>To use CUDA.jl, you&#39;ll need an Nvidia GPU and a recent version of the CUDA libraries. </p><p><em>NERSC-specific instructions:</em> On NERSC, just load the modules <code>cudnn/7.6.5</code> and <code>cuda/10.2.89</code> (other versions may work but those have been tested) and add <code>export JULIA_CUDA_USE_BINARYBUILDER=false</code> to your bashrc. </p><p>See also <a href="https://juliagpu.gitlab.io/CUDA.jl/installation/overview/">install instructions</a> for more info. </p><h2 id="CUDA-basics-1"><a class="docs-heading-anchor" href="#CUDA-basics-1">CUDA basics</a><a class="docs-heading-anchor-permalink" href="#CUDA-basics-1" title="Permalink"></a></h2><p>To start, load the packages. Note that due to some Julia intricasies, you must load CUDA first:</p><pre class="language-julia"><code class="language-julia">using CUDA, Adapt, CMBLensing, Random, PyPlot</code></pre><p>To check everything loaded correctly:</p><pre class="language-julia"><code class="language-julia">CUDA.device()</code></pre><pre class="language-output"><code class="language-output">CuDevice(0): Tesla V100-SXM2-16GB</code></pre><pre class="language-julia"><code class="language-julia">CUDA.functional()</code></pre><pre class="language-output"><code class="language-output">true</code></pre><p>CUDA.jl provides an array type called <code>CuArray</code> which is an array that resides on GPU. You can convert <code>Array</code>s to <code>CuArray</code>s via the <code>adapt</code> function:</p><pre class="language-julia"><code class="language-julia">x_cpu = rand(128,128)
x_gpu = adapt(CuArray, x_cpu)</code></pre><pre class="language-output"><code class="language-output">128Ã—128 CuArray{Float64,2}:
 0.0687061  0.323452  0.499862  0.201088  â€¦  0.953384   0.995337  0.167936
 0.549291   0.84707   0.13641   0.140519     0.0863971  0.976545  0.404249
 0.75233    0.344927  0.457225  0.473147     0.425078   0.580845  0.00607347
 â‹®                                        â‹±  â‹®                    
 0.823417   0.687004  0.655753  0.689161     0.337063   0.980848  0.753333
 0.283694   0.403416  0.87598   0.130036     0.753313   0.340956  0.400289</code></pre><p>Any operations you now to do <code>x_gpu</code> are done on GPU and are super fast (although benchmarking can be <a href="https://juliagpu.gitlab.io/CUDA.jl/development/profiling/">subtle</a>):</p><pre class="language-julia"><code class="language-julia">2 * x_gpu + x_gpu # happened on GPU</code></pre><pre class="language-output"><code class="language-output">128Ã—128 CuArray{Float64,2}:
 0.206118  0.970356  1.49959  0.603264  â€¦  2.86015   2.98601  0.503807
 1.64787   2.54121   0.40923  0.421558     0.259191  2.92964  1.21275
 2.25699   1.03478   1.37168  1.41944      1.27523   1.74254  0.0182204
 â‹®                                      â‹±  â‹®                  
 2.47025   2.06101   1.96726  2.06748      1.01119   2.94254  2.26
 0.851083  1.21025   2.62794  0.390108     2.25994   1.02287  1.20087</code></pre><p>Note also that <code>cu(x)</code> is shorthand for <code>adapt(CuArray{Float32}, x)</code>, and <code>cpu(x)</code> is shorthand for <code>adapt(Array, x)</code> which moves a GPU array back to CPU (generally there&#39;s not many situations where you need to explicitly do this). </p><h2 id="CMBLensing-GPU-basics-1"><a class="docs-heading-anchor" href="#CMBLensing-GPU-basics-1">CMBLensing GPU basics</a><a class="docs-heading-anchor-permalink" href="#CMBLensing-GPU-basics-1" title="Permalink"></a></h2><p>CMBLensing fields can be put on GPU in exactly the same way.</p><pre class="language-julia"><code class="language-julia">f_cpu = FlatMap(rand(128,128))
f_gpu = cu(f_cpu)</code></pre><pre class="language-output"><code class="language-output">16384-element FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, CuArray{Float32,2}}:
 0.10891746
 0.75744337
 0.72595507
 â‹®
 0.26491597
 0.5190752</code></pre><p>Everything you can do to a CPU Field object you can do to a GPU one. </p><pre class="language-julia"><code class="language-julia">f_gpu&#39; * (2 * Fourier(f_gpu))</code></pre><pre class="language-output"><code class="language-output">10944.155f0</code></pre><p><code>cu(x)</code> works recursively through most objects, for example through NamedTuples:</p><pre class="language-julia"><code class="language-julia">(x=f_cpu, y=f_cpu) |&gt; typeof</code></pre><pre class="language-output"><code class="language-output">NamedTuple{(:x, :y),Tuple{FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, Array{Float64,2}},FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, Array{Float64,2}}}}</code></pre><pre class="language-julia"><code class="language-julia">cu((x=f_cpu, y=f_cpu)) |&gt; typeof</code></pre><pre class="language-output"><code class="language-output">NamedTuple{(:x, :y),Tuple{FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, CuArray{Float32,2}},FlatMap{128Ã—128 map, 1â€² pixels, fourierâˆ‚, CuArray{Float32,2}}}}</code></pre><p>You can move an entire <code>DataSet</code> to GPU too with <code>cu(ds)</code>, which recursively moves all the fields and operators inside this object to GPU:</p><pre class="language-julia"><code class="language-julia">@unpack ds, Ï• = load_sim(Nside=256, Î¸pix=3, pol=:P);</code></pre><pre class="language-julia"><code class="language-julia">ds.d |&gt; typeof</code></pre><pre class="language-output"><code class="language-output">FlatEBFourier{256Ã—256 map, 3â€² pixels, fourierâˆ‚, Array{Complex{Float32},2}}</code></pre><pre class="language-julia"><code class="language-julia">cu(ds).d |&gt; typeof</code></pre><pre class="language-output"><code class="language-output">FlatEBFourier{256Ã—256 map, 3â€² pixels, fourierâˆ‚, CuArray{Complex{Float32},2}}</code></pre><p>Note that on NERSC, the <code>load_sim</code> command above is really slow because the GPU nodes only give you a few CPU cores per GPU (rather than the 64 cores you get on a CPU compute node). You can also generate the <code>DataSet</code> directly on GPU, which is much faster:</p><pre class="language-julia"><code class="language-julia">@unpack ds, Ï• = load_sim(Nside=256, Î¸pix=3, pol=:P, storage=CuArray);</code></pre><p>Once you have the <code>DataSet</code> object on GPU, all the normal high-level operations work on it, e.g.:</p><pre class="language-julia"><code class="language-julia">fJ,Ï•J = MAP_joint(ds, nsteps=10, progress=true);</code></pre><pre class="language-output"><code class="language-output">[32mMAP_joint: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| Time: 0:00:05[39m
[34m  step:  10[39m
[34m  Ï‡Â²:    132046.02[39m
[34m  Ncg:   2[39m</code></pre><pre class="language-julia"><code class="language-julia">plot([Ï• Ï•J])</code></pre><p><img src="../06_gpu_files/06_gpu_29_0.png" alt="png"/></p><h2 id="Batching-1"><a class="docs-heading-anchor" href="#Batching-1">Batching</a><a class="docs-heading-anchor-permalink" href="#Batching-1" title="Permalink"></a></h2><p>Just moving a <code>DataSet</code> to GPU will give you factors of about 2 - 10 speeds over CPU for <code>Nside</code> of 128 - 1024. You can go even faster by &quot;batching,&quot; which means doing the same operations to multiple fields at once, i.e. in &quot;batches&quot;. The trick is that for the full speedup, this parallelization has to happen on the inner-most-loop so that the GPU basically goes through the data all at once with a single GPU kernel. You do this by putting multiple fields into single &quot;batched fields&quot;. </p><p>Suppose you had 10 fields on GPU that you want to lense:</p><pre class="language-julia"><code class="language-julia">fs = [simulate(ds.Cf) for i=1:10]
Ï•s = [simulate(ds.CÏ•) for i=1:10];</code></pre><p>You could do the following, and it might still be a little faster than doing it sequentially:</p><pre class="language-julia"><code class="language-julia">fÌƒs = [LenseFlow(Ï•)*f for (f,Ï•) in zip(fs,Ï•s)];</code></pre><p>But the <em>really</em> fast way to do it is pack those 10 fields into a batched field (note the indication these are batched in the printed type information):</p><pre class="language-julia"><code class="language-julia">f_batch = batch(fs)</code></pre><pre class="language-output"><code class="language-output">660480(Ã—10)-element FlatEBFourier{256Ã—256(Ã—10) map, 3â€² pixels, fourierâˆ‚, CuArray{Complex{Float32},3}}:
          0.0f0 + 0.0f0im
     2231.683f0 + 1578.4241f0im
   -1101.9895f0 + 6993.024f0im
                â‹®
   0.07073971f0 + 0.12127238f0im
 -0.018757222f0 - 0.29610783f0im</code></pre><pre class="language-julia"><code class="language-julia">Ï•_batch = batch(Ï•s)</code></pre><pre class="language-output"><code class="language-output">330240(Ã—10)-element FlatFourier{256Ã—256(Ã—10) map, 3â€² pixels, fourierâˆ‚, CuArray{Complex{Float32},3}}:
         0.0f0 + 0.0f0im
  0.15543585f0 + 0.0040701367f0im
 0.049608342f0 - 0.11676395f0im
               â‹®
 -3.4914913f-7 + 7.705292f-7im
 -7.6260557f-7 + 3.076318f-7im</code></pre><p>And then run the lensing operation once, which will lense each of the 10 <code>f</code>s by the corresponding <code>Ï•</code>. </p><pre class="language-julia"><code class="language-julia">fÌƒ_batch = LenseFlow(Ï•_batch) * f_batch</code></pre><pre class="language-output"><code class="language-output">1310720(Ã—10)-element FlatQUMap{256Ã—256(Ã—10) map, 3â€² pixels, fourierâˆ‚, CuArray{Float32,3}}:
 -3.9583502
 -3.0105171
 -2.999421
  â‹®
  0.20551158
  0.5773034</code></pre><p>For the problem size of <code>Nside=256</code>, doing this batch of 10 lenses is almost no slower than doing a single one. </p><p>You can get the individual fields out of the batched result with <code>batchindex</code>, e.g. the first 2 (out of 10) lensed B fields:</p><pre class="language-julia"><code class="language-julia">plot([batchindex(fÌƒ_batch,1) batchindex(fÌƒ_batch, 2)], which=:Bx)</code></pre><p><img src="../06_gpu_files/06_gpu_42_0.png" alt="png"/></p><p>Normal broadcasting rules apply between batched and non-batched fields, so e.g.:</p><pre class="language-julia"><code class="language-julia">LenseFlow(Ï•) * f_batch</code></pre><pre class="language-output"><code class="language-output">1310720(Ã—10)-element FlatQUMap{256Ã—256(Ã—10) map, 3â€² pixels, fourierâˆ‚, CuArray{Float32,3}}:
 -4.148711
 -3.4063883
 -2.7889354
  â‹®
  0.9247154
 -0.82399666</code></pre><p>works and lenses the 10 different fields in <code>f_batch</code> by the <em>same</em> (non-batched) <code>Ï•</code>.</p><p>Most of CMBLensing works with batched fields just like with normal fields. This includes things like <code>lnP</code>, <code>conjugate_gradient</code> or <code>sample_joint</code>, although <code>MAP_joint</code> and <code>MAP_marg</code> only work with non-batched fields (but will be fixed in the future).</p><h2 id="Gotchas-1"><a class="docs-heading-anchor" href="#Gotchas-1">Gotchas</a><a class="docs-heading-anchor-permalink" href="#Gotchas-1" title="Permalink"></a></h2><p>Not much, hopefully. If something that works on CPU doesn&#39;t work on GPU, please file an Issue.</p><p>One thing to keep in mind is that CPU and GPU use different random number generators, so seeds will not correspond. Note however you can force a GPU simulation to use the CPU RNG by passing <code>rng=MersenneTwister()</code>.</p><pre class="language-julia"><code class="language-julia">plot([simulate(cpu(ds.CÏ•),seed=0) simulate(cu(ds.CÏ•),seed=0) simulate(cu(ds.CÏ•),seed=0,rng=MersenneTwister())])</code></pre><p><img src="../06_gpu_files/06_gpu_50_0.png" alt="png"/></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../05_field_basics/">Â« Field Basics</a><a class="docs-footer-nextpage" href="../api/">API Â»</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Saturday 28 November 2020 01:08">Saturday 28 November 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
