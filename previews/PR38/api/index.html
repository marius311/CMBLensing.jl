<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · CMBLensing.jl</title><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link href="../assets/cmblensing.css" rel="stylesheet" type="text/css"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">CMBLensing.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">CMBLensing.jl</a></li><li><a class="tocitem" href="../01_lense_a_map/">Lensing a flat-sky map</a></li><li><a class="tocitem" href="../02_posterior/">The Lensing Posterior</a></li><li><a class="tocitem" href="../03_joint_MAP_example/">MAP estimation</a></li><li><a class="tocitem" href="../04_from_python/">Calling from Python</a></li><li><a class="tocitem" href="../05_field_basics/">Field Basics</a></li><li><a class="tocitem" href="../06_gpu/">GPU</a></li><li class="is-active"><a class="tocitem" href>API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"></nav><div class="docs-right"><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="API-1"><a class="docs-heading-anchor" href="#API-1">API</a><a class="docs-heading-anchor-permalink" href="#API-1" title="Permalink"></a></h1><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.MAP_joint-Tuple{DataSet}" href="#CMBLensing.MAP_joint-Tuple{DataSet}"><code>CMBLensing.MAP_joint</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">MAP_joint(ds::DataSet; kwargs...)</code></pre><p>Compute the maximum a posteriori (i.e. &quot;MAP&quot;) estimate of the joint posterior, <span>$\mathcal{P}(f,\phi,\theta\,|\,d)$</span>, or compute a quasi-sample. </p><p>Keyword arguments:</p><ul><li><code>ϕstart</code> — Starting point of the maximizer <em>(default:</em> <span>$\phi=0$</span><em>)</em>.</li><li><code>nsteps</code> — The maximum number of iterations for the maximizer</li><li><code>ϕtol</code> — If given, stop when <span>$\phi$</span> updates reach this tolerance. <code>ϕtol</code> is roughly the relative per-pixel standard deviation between changes to <span>$\phi$</span> and draws from the <span>$\phi$</span> prior. Values in the range <span>$10^{-2}-10^{-4}$</span> are reasonable. </li><li><code>lbfgs_rank</code> — The maximum rank of the LBFGS approximation to the  Hessian *(default: 5).</li><li><code>conjgrad_kwargs</code> — Passed to the inner call to <a href="#CMBLensing.conjugate_gradient"><code>conjugate_gradient</code></a>.</li><li><code>progress</code> — Whether to show the progress bar.</li><li><code>Nϕ</code> — Noise to use in the initial approximation to the Hessian. Can  also give <code>Nϕ=:qe</code> to use the quadratic estimate noise <em>(default:</em>  <code>:qe</code><em>)</em>.</li><li><code>quasi_sample</code> — <code>false</code> <em>(default)</em> to compute the MAP, <code>true</code> to  iterate quasi-samples, or an integer to compute a fixed-seed  quasi-sample.</li><li><code>history_keys</code> — What quantities to include in the returned <code>history</code>. Can be any subset of <code>(:f, :f°, :ϕ, :∇ϕ_lnP, :χ², :lnP)</code>.</li></ul><p>Returns a tuple <code>(f, ϕ, history)</code> where <code>f</code> is the best-fit (or quasi-sample) field, <code>ϕ</code> is the lensing potential, and <code>history</code> contains the history of steps during the run. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.MAP_marg-Tuple{DataSet}" href="#CMBLensing.MAP_marg-Tuple{DataSet}"><code>CMBLensing.MAP_marg</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">MAP_marg(ds; kwargs...)</code></pre><p>Compute the maximum a posteriori (i.e. &quot;MAP&quot;) estimate of the marginal posterior, <span>$\mathcal{P}(\phi,\theta\,|\,d)$</span>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.argmaxf_lnP-Tuple{Field,DataSet}" href="#CMBLensing.argmaxf_lnP-Tuple{Field,DataSet}"><code>CMBLensing.argmaxf_lnP</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">argmaxf_lnP(ϕ,                ds::DataSet; kwargs...)
argmaxf_lnP(ϕ, θ::NamedTuple, ds::DataSet; kwargs...)
argmaxf_lnP(Lϕ,               ds::DataSet; kwargs...)</code></pre><p>Computes either the Wiener filter at fixed <span>$\phi$</span>, or a sample from this slice along the posterior.</p><p>Keyword arguments: </p><ul><li><code>which</code> — <code>:wf</code>, <code>:sample</code>, or <code>fluctuation</code> to compute 1) the Wiener filter, i.e. the best-fit of <span>$\mathcal{P}(f\,|\,\phi,d)$</span>, 2) a sample from <span>$\mathcal{P}(f\,|\,\phi,d)$</span>, or 3) a sample minus the Wiener filter, i.e. the fluctuation on top of the mean.</li><li><code>fstart</code> — starting guess for <code>f</code> for the conjugate gradient solver</li><li><code>conjgrad_kwargs</code> — Passed to the inner call to <a href="#CMBLensing.conjugate_gradient"><code>conjugate_gradient</code></a></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.batch-Union{Tuple{F}, Tuple{D′}, Tuple{∂m}, Tuple{θ}, Tuple{N}, Tuple{F,Int64}} where F&lt;:(Union{FlatFourier{Flat{N,θ,∂m,D′},T,M}, FlatMap{Flat{N,θ,∂m,D′},T,M}} where M where T) where D′ where ∂m where θ where N" href="#CMBLensing.batch-Union{Tuple{F}, Tuple{D′}, Tuple{∂m}, Tuple{θ}, Tuple{N}, Tuple{F,Int64}} where F&lt;:(Union{FlatFourier{Flat{N,θ,∂m,D′},T,M}, FlatMap{Flat{N,θ,∂m,D′},T,M}} where M where T) where D′ where ∂m where θ where N"><code>CMBLensing.batch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">batch(f::FlatField, D::Int)</code></pre><p>Construct a batch-length-<code>D</code> <code>FlatField</code> from an unbatched <code>FlatField</code> which will broadcast as if it were <code>D</code> copies of <code>f</code> (without actually making <code>D</code> copies of the data in <code>f</code>)</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.batch-Union{Tuple{F}, Tuple{F}, Tuple{∂m}, Tuple{θ}, Tuple{N}} where F&lt;:(Union{FlatFourier{var&quot;#s359&quot;,T,M}, FlatMap{var&quot;#s359&quot;,T,M}} where M where T where var&quot;#s359&quot;&lt;:(Flat{N,θ,∂m,D} where D)) where ∂m where θ where N" href="#CMBLensing.batch-Union{Tuple{F}, Tuple{F}, Tuple{∂m}, Tuple{θ}, Tuple{N}} where F&lt;:(Union{FlatFourier{var&quot;#s359&quot;,T,M}, FlatMap{var&quot;#s359&quot;,T,M}} where M where T where var&quot;#s359&quot;&lt;:(Flat{N,θ,∂m,D} where D)) where ∂m where θ where N"><code>CMBLensing.batch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">batch(fs::FlatField...)
batch(fs::Vector{&lt;:FlatField})
batch(fs::TUple{&lt;:FlatField})</code></pre><p>Turn a length-N array of <code>FlatField</code>&#39;s into a single batch-length-N <code>FlatField</code>. For the inverse operation, see <a href="#CMBLensing.unbatch-Tuple{CMBLensing.Chains}"><code>unbatch</code></a>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.batchindex-Union{Tuple{F}, Tuple{P}, Tuple{∂mode}, Tuple{θ}, Tuple{N}, Tuple{F,Any}} where F&lt;:(Union{FlatFourier{P,T,M}, FlatMap{P,T,M}} where M where T) where P&lt;:(Flat{N,θ,∂mode,D} where D) where ∂mode where θ where N" href="#CMBLensing.batchindex-Union{Tuple{F}, Tuple{P}, Tuple{∂mode}, Tuple{θ}, Tuple{N}, Tuple{F,Any}} where F&lt;:(Union{FlatFourier{P,T,M}, FlatMap{P,T,M}} where M where T) where P&lt;:(Flat{N,θ,∂mode,D} where D) where ∂mode where θ where N"><code>CMBLensing.batchindex</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">batchindex(f::FlatField, I)</code></pre><p>Get the <code>I</code>th indexed batch (<code>I</code> can be a slice). </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.batchsize-Union{Tuple{Union{FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,EBFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,QUFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,EBMap}},NamedTuple{(:I, :P),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}}},T}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,QUMap}},NamedTuple{(:I, :P),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}}},T}, FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}, FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}, FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}, FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}, FlatFourier{var&quot;#s139&quot;,T,M}, FlatMap{var&quot;#s139&quot;,T,M}} where M where T where var&quot;#s139&quot;&lt;:(Flat{var&quot;#s138&quot;,var&quot;#s137&quot;,var&quot;#s136&quot;,D} where var&quot;#s136&quot; where var&quot;#s137&quot; where var&quot;#s138&quot;)}, Tuple{D}} where D" href="#CMBLensing.batchsize-Union{Tuple{Union{FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,EBFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,QUFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,EBMap}},NamedTuple{(:I, :P),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}}},T}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,QUMap}},NamedTuple{(:I, :P),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}}},T}, FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}, FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}, FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}, FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}, FlatFourier{var&quot;#s139&quot;,T,M}, FlatMap{var&quot;#s139&quot;,T,M}} where M where T where var&quot;#s139&quot;&lt;:(Flat{var&quot;#s138&quot;,var&quot;#s137&quot;,var&quot;#s136&quot;,D} where var&quot;#s136&quot; where var&quot;#s137&quot; where var&quot;#s138&quot;)}, Tuple{D}} where D"><code>CMBLensing.batchsize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">batchsize(f::FlatField)</code></pre><p>The size of the batch dimension of this object.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.beamCℓs-Tuple{}" href="#CMBLensing.beamCℓs-Tuple{}"><code>CMBLensing.beamCℓs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">beamCℓs(;beamFWHM, ℓmax=8000)</code></pre><p>Compute the beam power spectrum, often called <span>$W_\ell$</span>. A map should be multiplied by the square root of this.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.cpu-Tuple{Any}" href="#CMBLensing.cpu-Tuple{Any}"><code>CMBLensing.cpu</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">cpu(xs)</code></pre><p>Recursively move an object to CPU memory (i.e. the opposite of <code>cu</code>)</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.fixed_white_noise-Tuple{Any,Type{var&quot;#s359&quot;} where var&quot;#s359&quot;&lt;:(Union{FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,EBFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{P,T,M},FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{P,T,M},FlatFourier{P,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,QUFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{P,T,M},FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{P,T,M},FlatFourier{P,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{P,T,M},FlatFourier{P,T,M}}},Complex{T}}, FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{P,T,M},FlatMap{P,T,M}}},T}, FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{P,T,M},FlatFourier{P,T,M}}},Complex{T}}, FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{P,T,M},FlatMap{P,T,M}}},T}, FlatFourier{P,T,M}} where M where T where P)}" href="#CMBLensing.fixed_white_noise-Tuple{Any,Type{var&quot;#s359&quot;} where var&quot;#s359&quot;&lt;:(Union{FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,EBFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{P,T,M},FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{P,T,M},FlatFourier{P,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,QUFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{P,T,M},FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{P,T,M},FlatFourier{P,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{P,T,M},FlatFourier{P,T,M}}},Complex{T}}, FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{P,T,M},FlatMap{P,T,M}}},T}, FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{P,T,M},FlatFourier{P,T,M}}},Complex{T}}, FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{P,T,M},FlatMap{P,T,M}}},T}, FlatFourier{P,T,M}} where M where T where P)}"><code>CMBLensing.fixed_white_noise</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">fixed_white_noise(rng, F)</code></pre><p>Like white noise but the amplitudes are fixed to unity, only the phases are random. Currently only implemented when F is a Fourier basis. Note that unlike <a href="@ref"><code>white_noise</code></a>, fixed white-noise generated in EB and QU Fourier bases are not statistically the same.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.gradhess-Tuple{Any}" href="#CMBLensing.gradhess-Tuple{Any}"><code>CMBLensing.gradhess</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">gradhess(f)</code></pre><p>Compute the gradient <span>$g^i = \nabla^i f$</span>, and the hessian, <span>$H_j^{\,i} = \nabla_j \nabla^i f$</span>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.lnP-Tuple{Any,Any,Any,DataSet}" href="#CMBLensing.lnP-Tuple{Any,Any,Any,DataSet}"><code>CMBLensing.lnP</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">lnP(t, fₜ, ϕₜ,                ds::DataSet)
lnP(t, fₜ, ϕₜ, θ::NamedTuple, ds::DataSet)</code></pre><p>Compute the log posterior probability in the joint parameterization as a function of the field, <span>$f_t$</span>, the lensing potential, <span>$\phi_t$</span>, and possibly some cosmological parameters, <span>$\theta$</span>. The subscript <span>$t$</span> can refer to either a &quot;time&quot;, e.g. passing <code>t=0</code> corresponds to the unlensed parametrization and <code>t=1</code> to the lensed one, or can be <code>:mix</code> correpsonding to the mixed parametrization. In all cases, the arguments <code>fₜ</code> and <code>ϕₜ</code> should then be <span>$f$</span> and <span>$\phi$</span> in that particular parametrization.</p><p>If any parameters <span>$\theta$</span> are provided, we also include the determinant terms for covariances which depend on <span>$\theta$</span>. In the mixed parametrization, we also include any Jacobian determinant terms that depend on <span>$\theta$</span>. </p><p>The argument <code>ds</code> should be a <code>DataSet</code> and stores the masks, data, etc... needed to construct the posterior. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.load_camb_Cℓs-Tuple{}" href="#CMBLensing.load_camb_Cℓs-Tuple{}"><code>CMBLensing.load_camb_Cℓs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">load_camb_Cℓs(;path_prefix, custom_tensor_params=nothing, 
    unlensed_scalar_postfix, unlensed_tensor_postfix, lensed_scalar_postfix, lenspotential_postfix)</code></pre><p>Load some Cℓs from CAMB files. </p><p><code>path_prefix</code> specifies the prefix for the files, which are then expected to have the normal CAMB postfixes: &quot;scalCls.dat&quot;, &quot;tensCls.dat&quot;, &quot;lensedCls.dat&quot;, &quot;lenspotentialCls.dat&quot;, unless otherwise specified via the other keyword arguments. <code>custom_tensor_params</code> can be used to call CAMB directly for the unlensed<em>tensors, rather than reading them from a file (since alot of times this file doesn&#39;t get saved). The value should be a Dict/NamedTuple which will be passed to a call to <a href="@ref"><code>camb</code></a>, e.g. `custom</em>tensor_params=(r=0,)` for zero tensors. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.load_chains-Tuple{Any}" href="#CMBLensing.load_chains-Tuple{Any}"><code>CMBLensing.load_chains</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">load_chains(filename; burnin=0, burnin_chunks=0, thin=1, join=false, unbatch=true)</code></pre><p>Load a single chain or multiple parallel chains which were written to a file by <a href="#CMBLensing.sample_joint-Tuple{DataSet}"><code>sample_joint</code></a>. </p><p>Keyword arguments: </p><ul><li><code>burnin</code> — Remove this many samples from the start of each chain, or if negative, keep only this many samples at the end of each chain.</li><li><code>burnin_chunks</code> — Same as burnin, but in terms of chain &quot;chunks&quot; stored in the chain file, rather than in terms of samples.</li><li><code>thin</code> — If <code>thin</code> is an integer, thin the chain by this factor. If <code>thin == :hasmaps</code>, return only samples which have maps saved. If thin is a <code>Function</code>, filter the chain by this function (e.g. <code>thin=haskey(:g)</code> on Julia 1.5+)</li><li><code>unbatch</code> — If true, <a href="@ref">unbatch</a> the chains if they are batched.</li><li><code>join</code> — If true, concatenate all the chains together.</li><li><code>skip_missing_chunks</code> — Skip missing chunks in the chain instead of terminating the chain there. </li></ul><p>The object returned by this function is a <code>Chain</code> or <code>Chains</code> object, which simply wraps an <code>Array</code> of <code>Dicts</code> or an <code>Array</code> of <code>Array</code> of <code>Dicts</code>, respectively (each sample is a <code>Dict</code>). The wrapper object has some extra indexing properties for convenience: </p><ul><li>It can be indexed as if it were a single multidimensional object, e.g. <code>chains[1,:,:accept]</code> would return the <code>:accept</code> key of all samples in the first chain.</li><li>Leading colons can be dropped, i.e. <code>chains[:,:,:accept]</code> is the same as <code>chains[:accept]</code>. </li><li>If some samples are missing a particular key, <code>missing</code> is returned for those samples insted of an error.</li><li>The recursion goes arbitrarily deep into the objects it finds. E.g., since sampled parameters are stored in a <code>NamedTuple</code> like <code>(Aϕ=1.3,)</code> in the <code>θ</code> key of each sample <code>Dict</code>, you can do <code>chain[:θ,:Aϕ]</code> to get all <code>Aϕ</code> samples as a vector. </li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.load_sim-Tuple{}" href="#CMBLensing.load_sim-Tuple{}"><code>CMBLensing.load_sim</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">load_sim</code></pre><p>Create a <code>BaseDataSet</code> object with some simulated data, returing the DataSet and simulated truths. E.g.</p><pre class="language-julia"><code class="language-julia">@unpack f,ϕ,ds = load_sim(;
    θpix  = 2,
    Nside = 128,
    pol   = :I,
    T     = Float32
);</code></pre><p>For rectangular maps, Nside expects (Ny, Nx), i.e. (Nrow, Ncol).  If Nside isa Int, the code interprets it as a square map.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.mean_std_and_errors-Tuple{Any}" href="#CMBLensing.mean_std_and_errors-Tuple{Any}"><code>CMBLensing.mean_std_and_errors</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">mean_std_and_errors(samples; N_bootstrap=10000)</code></pre><p>Get the mean and standard deviation of a set of correlated <code>samples</code> from a chain where the error on the mean and standard deviation is estimated with bootstrap resampling using the calculated &quot;effective sample size&quot; of the chain.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.mix-Tuple{Any,Any,DataSet}" href="#CMBLensing.mix-Tuple{Any,Any,DataSet}"><code>CMBLensing.mix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">mix(f, ϕ,                ds::DataSet)
mix(f, ϕ, θ::NamedTuple, ds::DataSet)</code></pre><p>Compute the mixed <code>(f°, ϕ°)</code> from the unlensed field <code>f</code> and lensing potential <code>ϕ</code>, given the definition of the mixing matrices in <code>ds</code> evaluated at parameters <code>θ</code> (or at fiducial values if no <code>θ</code> provided).</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.noiseCℓs-Tuple{}" href="#CMBLensing.noiseCℓs-Tuple{}"><code>CMBLensing.noiseCℓs</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">noiseCℓs(;μKarcminT, beamFWHM=0, ℓmax=8000, ℓknee=100, αknee=3)</code></pre><p>Compute the (:TT,:EE,:BB,:TE) noise power spectra given white noise + 1/f. Polarization noise is scaled by <span>$\sqrt{2}$</span> relative to <code>μKarcminT</code>. <code>beamFWHM</code> is in arcmin.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.pixwin-Tuple{Any,Any}" href="#CMBLensing.pixwin-Tuple{Any,Any}"><code>CMBLensing.pixwin</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">pixwin(θpix, ℓ)</code></pre><p>Returns the pixel window function for square flat-sky pixels of width <code>θpix</code> (in arcmin) evaluated at some <code>ℓ</code>s. This is the scaling of k-modes, the scaling of the power spectrum will be pixwin^2. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.quadratic_estimate-Union{Tuple{F2}, Tuple{F1}, Tuple{Tuple{DataSet,DataSet},Any}} where F2 where F1" href="#CMBLensing.quadratic_estimate-Union{Tuple{F2}, Tuple{F1}, Tuple{Tuple{DataSet,DataSet},Any}} where F2 where F1"><code>CMBLensing.quadratic_estimate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">quadratic_estimate(ds::DataSet, which; wiener_filtered=true)
quadratic_estimate((ds1::DataSet,ds2::DataSet), which; wiener_filtered=true)</code></pre><p>Compute quadratic estimate of ϕ given data.</p><p>The <code>ds</code> or <code>(ds1,ds2)</code> tuple contain the DataSet object(s) which houses the data and covariances used in the estimate. Note that only the Fourier-diagonal approximations for the beam, mask, and noise,, i.e. <code>ds.B̂</code>, <code>ds.M̂</code>, and <code>ds.Cn̂</code>, are accounted for. To account full operators (if they are not actually Fourier-diagonal), you should compute the impact using Monte Carlo.</p><p>If a tuple is passed in, the result will come from correlating the data from <code>ds1</code> with that from <code>ds2</code>, which can be useful for debugging / isolating various noise terms. </p><p>An optional keyword argument <code>AL</code> can be passed in in case the QE normalization was already computed, in which case it won&#39;t be recomputed during the calculation.</p><p>Returns a NamedTuple <code>(ϕqe, AL, Nϕ)</code> where <code>ϕqe</code> is the (possibly Wiener filtered, depending on <code>wiener_filtered</code> option) quadratic estimate, <code>AL</code> is the normalization (which is already applied to ϕqe, it does not need to be applied again), and <code>Nϕ</code> is the analytic N0 noise bias (Nϕ==AL if using unlensed weights, currently only Nϕ==AL is always returned, no matter the weights)</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.resimulate!-Tuple{DataSet}" href="#CMBLensing.resimulate!-Tuple{DataSet}"><code>CMBLensing.resimulate!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">resimulate!(ds::DataSet; [f, ϕ, n])</code></pre><p>Replace the data in this DataSet in-place with a simulation, potentially given a fixed f, ϕ, or n, if any are provided. </p><p>Returns a named tuple of <code>(ds, f, ϕ, n, f̃)</code></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.resimulate-Tuple{DataSet}" href="#CMBLensing.resimulate-Tuple{DataSet}"><code>CMBLensing.resimulate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">resimulate(ds::DataSet; [f, ϕ, n])</code></pre><p>Make a new DataSet with the data replaced by a simulation, potentially given a fixed f, ϕ, or n, if any are provided. </p><p>Returns a named tuple of <code>(ds, f, ϕ, n, f̃)</code></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.sample_joint-Tuple{DataSet}" href="#CMBLensing.sample_joint-Tuple{DataSet}"><code>CMBLensing.sample_joint</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">sample_joint(ds::DataSet; kwargs...)</code></pre><p>Sample the joint posterior, <span>$\mathcal{P}(f,\phi,\theta\,|\,d)$</span>. </p><p>Keyword arguments: </p><ul><li><code>nsamps_per_chain</code> — <em>(required)</em> The number of samples per chain</li><li><code>nchains</code> — Run <code>nchains</code> chains in parallel <em>(default: 1)</em></li><li><code>nchunk</code> — Do <code>nchunk</code> steps between parallel chain communication <em>(default: 1)</em></li><li><code>nsavemaps</code> — Save maps into chain every <code>nsavemaps</code> steps <em>(default: 1)</em></li><li><code>nburnin_always_accept</code> — The first <code>nburnin_always_accept</code> steps, always accept                           HMC steps independent of integration error <em>(default: 0)</em></li><li><code>nburnin_fixθ</code> — For the first <code>nburnin_fixθ</code> steps, fix θ at its starting point <em>(default: 0)</em></li><li><code>Nϕ</code> — Noise to use in the HMC mass matrix. can also give <code>Nϕ=:qe</code> to use the         EB quadratic estimate noise <em>(default: <code>:qe</code>)</em></li><li><code>chains</code> — <code>nothing</code> to start a new chain; the return value from a previous call to            <code>sample_joint</code> to resume those chains; <code>:resume</code> to resume chains            from a file given by <code>filename</code></li><li><code>θrange</code> — Range and density to grid sample parameters as a NamedTuple,             e.g. <code>(Aϕ=range(0.7,1.3,length=20),)</code>. </li><li><code>θstart</code> — Starting values of parameters as a NamedTuple, e.g. <code>(Aϕ=1.2,)</code>,             or nothing to randomly sample from θrange</li><li><code>ϕstart</code> — Starting ϕ, either a <code>Field</code> object, <code>:quasi_sample</code>, or <code>:best_fit</code></li><li><code>metadata</code> — Does nothing, but is saved into the chain file</li><li><code>nhmc</code> — The number of HMC passes per ϕ Gibbs step <em>(default: 1)</em></li><li><code>symp_kwargs</code> — an array of NamedTupe kwargs to pass to <a href="#CMBLensing.symplectic_integrate-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any,Any}, Tuple{AbstractArray{T,1},Any,Any,Any,Any}} where T"><code>symplectic_integrate</code></a>.                  E.g. <code>[(N=50,ϵ=0.1),(N=25,ϵ=0.01)]</code> would do 50 large steps then 25                  smaller steps per each Gibbs pass. If specified, <code>nhmc</code> is ignored.</li><li><code>wf_kwargs</code> — Keyword arguments to pass to <a href="#CMBLensing.argmaxf_lnP-Tuple{Field,DataSet}"><code>argmaxf_lnP</code></a> in the Wiener Filter Gibbs step.</li><li><code>MAP_kwargs</code> — Keyword arguments to pass to <a href="#CMBLensing.MAP_joint-Tuple{DataSet}"><code>MAP_joint</code></a> when computing the starting point.</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.seed_for_storage!" href="#CMBLensing.seed_for_storage!"><code>CMBLensing.seed_for_storage!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre class="language-julia"><code class="language-julia">seed_for_storage!(storage[, seed])
seed_for_storage!((storage1, storage2, ...)[, seed])</code></pre><p>Set the global random seed for the RNG which controls <code>storage</code>-type. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.simulate-Tuple{Any}" href="#CMBLensing.simulate-Tuple{Any}"><code>CMBLensing.simulate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">simulate(Σ; rng=global_rng_for(Σ), seed=nothing)</code></pre><p>Draw a simulation from the covariance matrix <code>Σ</code>, i.e. draw a random vector <span>$\xi$</span> such that the covariance <span>$\langle \xi \xi^\dagger \rangle = \Sigma$</span>. </p><p>The random number generator <code>rng</code> will be used and advanced in the proccess, and is by default the appropriate one depending on if <code>Σ</code> is backed by <code>Array</code> or <code>CuArray</code>.</p><p>The <code>seed</code> argument can also be used to seed the <code>rng</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.symplectic_integrate-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any,Any}, Tuple{AbstractArray{T,1},Any,Any,Any,Any}} where T" href="#CMBLensing.symplectic_integrate-Union{Tuple{T}, Tuple{AbstractArray{T,1},Any,Any,Any}, Tuple{AbstractArray{T,1},Any,Any,Any,Any}} where T"><code>CMBLensing.symplectic_integrate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">symplectic_integrate(x₀, p₀, Λ, U, δUδx, N=50, ϵ=0.1, progress=false)</code></pre><p>Do a symplectic integration of the potential energy <code>U</code> (with gradient <code>δUδx</code>) starting from point <code>x₀</code> with momentum <code>p₀</code> and mass matrix <code>Λ</code>. The number of steps is <code>N</code> and the step size <code>ϵ</code>. </p><p>Returns <code>ΔH, xᵢ, pᵢ</code> corresponding to change in Hamiltonian, and final position and momenta. If <code>history_keys</code> is specified a history of requested variables throughout each step is also returned. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.ud_grade-Union{Tuple{P}, Tuple{∂mode}, Tuple{N}, Tuple{θ}, Tuple{M}, Tuple{T}, Tuple{Union{FlatFourier{P,T,M}, FlatMap{P,T,M}},Any}} where P&lt;:(Flat{N,θ,∂mode,D} where D) where ∂mode where N where θ where M where T" href="#CMBLensing.ud_grade-Union{Tuple{P}, Tuple{∂mode}, Tuple{N}, Tuple{θ}, Tuple{M}, Tuple{T}, Tuple{Union{FlatFourier{P,T,M}, FlatMap{P,T,M}},Any}} where P&lt;:(Flat{N,θ,∂mode,D} where D) where ∂mode where N where θ where M where T"><code>CMBLensing.ud_grade</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">ud_grade(f::Field, θnew, mode=:map, deconv_pixwin=true, anti_aliasing=true)</code></pre><p>Up- or down-grades field <code>f</code> to new resolution <code>θnew</code> (only in integer steps). Two modes are available specified by the <code>mode</code> argument: </p><ul><li><code>:map</code>     — Up/downgrade by replicating/averaging pixels in map-space</li><li><code>:fourier</code> — Up/downgrade by extending/truncating the Fourier grid</li></ul><p>For <code>:map</code> mode, two additional options are possible. If <code>deconv_pixwin</code> is true, deconvolves the pixel window function from the downgraded map so the spectrum of the new and old maps are the same. If <code>anti_aliasing</code> is true, filters out frequencies above Nyquist prior to down-sampling. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.unbatch-Tuple{CMBLensing.Chains}" href="#CMBLensing.unbatch-Tuple{CMBLensing.Chains}"><code>CMBLensing.unbatch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">unbatch(chains::Chains)</code></pre><p>Expand each chain in this <code>Chains</code> object by unbatching it. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.unbatch-Tuple{CMBLensing.Chain}" href="#CMBLensing.unbatch-Tuple{CMBLensing.Chain}"><code>CMBLensing.unbatch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">unbatch(chain::Chain)</code></pre><p>Convert a chain of batch-length-<code>D</code> fields to <code>D</code> chains of unbatched fields. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.unbatch-Tuple{Union{FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,EBFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,QUFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,EBMap}},NamedTuple{(:I, :P),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}}},T}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,QUMap}},NamedTuple{(:I, :P),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}}},T}, FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}, FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}, FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}, FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}, FlatFourier{var&quot;#s139&quot;,T,M}, FlatMap{var&quot;#s139&quot;,T,M}} where M where T where var&quot;#s139&quot;&lt;:(Flat{var&quot;#s138&quot;,var&quot;#s137&quot;,var&quot;#s136&quot;,1} where var&quot;#s136&quot; where var&quot;#s137&quot; where var&quot;#s138&quot;)}" href="#CMBLensing.unbatch-Tuple{Union{FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,EBFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Fourier,QUFourier}},NamedTuple{(:I, :P),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}}},Complex{T}}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,EBMap}},NamedTuple{(:I, :P),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}}},T}, FieldTuple{CMBLensing.BasisTuple{Tuple{Map,QUMap}},NamedTuple{(:I, :P),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}}},T}, FieldTuple{EBFourier,NamedTuple{(:E, :B),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}, FieldTuple{EBMap,NamedTuple{(:E, :B),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}, FieldTuple{QUFourier,NamedTuple{(:Q, :U),Tuple{FlatFourier{var&quot;#s139&quot;,T,M},FlatFourier{var&quot;#s139&quot;,T,M}}},Complex{T}}, FieldTuple{QUMap,NamedTuple{(:Q, :U),Tuple{FlatMap{var&quot;#s139&quot;,T,M},FlatMap{var&quot;#s139&quot;,T,M}}},T}, FlatFourier{var&quot;#s139&quot;,T,M}, FlatMap{var&quot;#s139&quot;,T,M}} where M where T where var&quot;#s139&quot;&lt;:(Flat{var&quot;#s138&quot;,var&quot;#s137&quot;,var&quot;#s136&quot;,1} where var&quot;#s136&quot; where var&quot;#s137&quot; where var&quot;#s138&quot;)}"><code>CMBLensing.unbatch</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">unbatch(f::FlatField)</code></pre><p>If <code>f</code> is a batch-length-<code>D</code> field, return length-<code>D</code> vector of each batch component, otherwise just return <code>f</code>. For the inverse operation, see <a href="#CMBLensing.batch-Union{Tuple{F}, Tuple{D′}, Tuple{∂m}, Tuple{θ}, Tuple{N}, Tuple{F,Int64}} where F&lt;:(Union{FlatFourier{Flat{N,θ,∂m,D′},T,M}, FlatMap{Flat{N,θ,∂m,D′},T,M}} where M where T) where D′ where ∂m where θ where N"><code>batch</code></a>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.unmix-Tuple{Any,Any,DataSet}" href="#CMBLensing.unmix-Tuple{Any,Any,DataSet}"><code>CMBLensing.unmix</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">unmix(f°, ϕ°,                ds::DataSet)
unmix(f°, ϕ°, θ::NamedTuple, ds::DataSet)</code></pre><p>Compute the unmixed/unlensed <code>(f, ϕ)</code> from the mixed field <code>f°</code> and mixed lensing potential <code>ϕ°</code>, given the definition of the mixing matrices in <code>ds</code> evaluated at parameters <code>θ</code> (or at fiducial values if no <code>θ</code> provided). </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.BilinearLens" href="#CMBLensing.BilinearLens"><code>CMBLensing.BilinearLens</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia">BilinearLens(ϕ)</code></pre><p>BilinearLens is a lensing operator that computes lensing with bilinear interpolation. The action of the operator, as well as its adjoint, inverse, inverse-adjoint, and gradient w.r.t. ϕ can all be computed. The log-determinant of the operation is non-zero and can&#39;t be computed. </p><p>Internally, BilinearLens forms a sparse matrix with the interpolation weights, which can be applied and adjoint-ed extremely fast (e.g. at least an order of magnitude faster than LenseFlow). Inverse and inverse-adjoint lensing is somewhat slower as it is implemented with several steps of the <a href="https://en.wikipedia.org/wiki/Generalized_minimal_residual_method">preconditioned generalized minimal residual</a> algorithm, taking anti-lensing as the preconditioner.</p><div class="admonition is-warning"><header class="admonition-header">Warning</header><div class="admonition-body"><p>Due to <a href="https://github.com/JuliaLang/PackageCompiler.jl/issues/379">this bug</a> in PackageCompiler, currently you have to run <code>using SparseArrays</code> by hand in your Julia session before <code>BilinearLens</code> is available.</p></div></div></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatEBFourier" href="#CMBLensing.FlatEBFourier"><code>CMBLensing.FlatEBFourier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructor:
FlatEBFourier(
    El::AbstractArray, Bl::AbstractArray; 
    Nside, # required, size of the map in pixels
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)

# more low-level:
FlatEBFourier{P}(El::AbstractArray, Bl::AbstractArray) # specify pixelization P explicilty
FlatEBFourier{P,T}(El::AbstractArray, Bl::AbstractArray) # additionally, convert elements to type Complex{T}
FlatEBFourier{P,T,M&lt;:AbstractArray{Complex{T}}}(El::M, Bl::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatEBFourier</code> object. The top form of the constructor is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatEBMap" href="#CMBLensing.FlatEBMap"><code>CMBLensing.FlatEBMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructor:
FlatEBMap(
    Ex::AbstractArray, Bx::AbstractArray; 
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)

# more low-level:
FlatEBMap{P}(Ex::AbstractArray, Bx::AbstractArray) # specify pixelization P explicilty
FlatEBMap{P,T}(Ex::AbstractArray, Bx::AbstractArray) # additionally, convert elements to type T
FlatEBMap{P,T,M&lt;:AbstractArray{T}}(Ex::M, Bx::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatEBMap</code> object. The top form of the constructor is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatFourier" href="#CMBLensing.FlatFourier"><code>CMBLensing.FlatFourier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructor:
FlatFourier(
    Il::AbstractArray; 
    Nside, # required, size of the map in pixels
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)

# more low-level:
FlatFourier{P}(Il::AbstractArray) # specify pixelization P explicilty
FlatFourier{P,T}(Il::AbstractArray) # additionally, convert elements to type Complex{T}
FlatFourier{P,T,M&lt;:AbstractArray{Complex{T}}}(Il::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatFourier</code> object. The top form of the constructor is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatIEBFourier" href="#CMBLensing.FlatIEBFourier"><code>CMBLensing.FlatIEBFourier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructors:
FlatIEBFourier(
    Il::AbstractMatrix, El::AbstractMatrix, Bl::AbstractMatrix; 
    Nside, # required, size of the map in pixels
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)
FlatIEBFourier(I::FlatFourier, E::FlatFourier, B::FlatFourier)

# more low-level:
FlatIEBFourier{P}(Il::AbstractMatrix, El::AbstractMatrix, Bl::AbstractMatrix) # specify pixelization P explicilty
FlatIEBFourier{P,T}(Il::AbstractMatrix, El::AbstractMatrix, Bl::AbstractMatrix) # additionally, convert elements to type Complex{T}
FlatIEBFourier{P,T,M&lt;:AbstractMatrix{Complex{T}}}(Il::M, El::M, Bl::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatIEBFourier</code> object. The top form of the constructors is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatIEBMap" href="#CMBLensing.FlatIEBMap"><code>CMBLensing.FlatIEBMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructors:
FlatIEBMap(
    Ix::AbstractMatrix, Ex::AbstractMatrix, Bx::AbstractMatrix; 
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)
FlatIEBMap(I::FlatMap, E::FlatMap, B::FlatMap)

# more low-level:
FlatIEBMap{P}(Ix::AbstractMatrix, Ex::AbstractMatrix, Bx::AbstractMatrix) # specify pixelization P explicilty
FlatIEBMap{P,T}(Ix::AbstractMatrix, Ex::AbstractMatrix, Bx::AbstractMatrix) # additionally, convert elements to type T
FlatIEBMap{P,T,M&lt;:AbstractMatrix{T}}(Ix::M, Ex::M, Bx::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatIEBMap</code> object. The top form of the constructors is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatIQUFourier" href="#CMBLensing.FlatIQUFourier"><code>CMBLensing.FlatIQUFourier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructors:
FlatIQUFourier(
    Il::AbstractMatrix, Ql::AbstractMatrix, Ul::AbstractMatrix; 
    Nside, # required, size of the map in pixels
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)
FlatIQUFourier(I::FlatFourier, Q::FlatFourier, U::FlatFourier)

# more low-level:
FlatIQUFourier{P}(Il::AbstractMatrix, Ql::AbstractMatrix, Ul::AbstractMatrix) # specify pixelization P explicilty
FlatIQUFourier{P,T}(Il::AbstractMatrix, Ql::AbstractMatrix, Ul::AbstractMatrix) # additionally, convert elements to type Complex{T}
FlatIQUFourier{P,T,M&lt;:AbstractMatrix{Complex{T}}}(Il::M, Ql::M, Ul::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatIQUFourier</code> object. The top form of the constructors is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatIQUMap" href="#CMBLensing.FlatIQUMap"><code>CMBLensing.FlatIQUMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructors:
FlatIQUMap(
    Ix::AbstractMatrix, Qx::AbstractMatrix, Ux::AbstractMatrix; 
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)
FlatIQUMap(I::FlatMap, Q::FlatMap, U::FlatMap)

# more low-level:
FlatIQUMap{P}(Ix::AbstractMatrix, Qx::AbstractMatrix, Ux::AbstractMatrix) # specify pixelization P explicilty
FlatIQUMap{P,T}(Ix::AbstractMatrix, Qx::AbstractMatrix, Ux::AbstractMatrix) # additionally, convert elements to type T
FlatIQUMap{P,T,M&lt;:AbstractMatrix{T}}(Ix::M, Qx::M, Ux::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatIQUMap</code> object. The top form of the constructors is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatMap" href="#CMBLensing.FlatMap"><code>CMBLensing.FlatMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructor:
FlatMap(
    Ix::AbstractArray; 
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)

# more low-level:
FlatMap{P}(Ix::AbstractArray) # specify pixelization P explicilty
FlatMap{P,T}(Ix::AbstractArray) # additionally, convert elements to type T
FlatMap{P,T,M&lt;:AbstractArray{T}}(Ix::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatMap</code> object. The top form of the constructor is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatQUFourier" href="#CMBLensing.FlatQUFourier"><code>CMBLensing.FlatQUFourier</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructor:
FlatQUFourier(
    Ql::AbstractArray, Ul::AbstractArray; 
    Nside, # required, size of the map in pixels
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)

# more low-level:
FlatQUFourier{P}(Ql::AbstractArray, Ul::AbstractArray) # specify pixelization P explicilty
FlatQUFourier{P,T}(Ql::AbstractArray, Ul::AbstractArray) # additionally, convert elements to type Complex{T}
FlatQUFourier{P,T,M&lt;:AbstractArray{Complex{T}}}(Ql::M, Ul::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatQUFourier</code> object. The top form of the constructor is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FlatQUMap" href="#CMBLensing.FlatQUMap"><code>CMBLensing.FlatQUMap</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia"># main constructor:
FlatQUMap(
    Qx::AbstractArray, Ux::AbstractArray; 
    θpix,  # optional, resolution in arcmin (default: 1)
    ∂mode, # optional, fourier∂ or map∂ (default: fourier∂)
)

# more low-level:
FlatQUMap{P}(Qx::AbstractArray, Ux::AbstractArray) # specify pixelization P explicilty
FlatQUMap{P,T}(Qx::AbstractArray, Ux::AbstractArray) # additionally, convert elements to type T
FlatQUMap{P,T,M&lt;:AbstractArray{T}}(Qx::M, Ux::M) # specify everything explicilty</code></pre><p>Construct a <code>FlatQUMap</code> object. The top form of the constructor is most convenient for interactive work, while the others may be more useful for low-level code.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.ParamDependentOp" href="#CMBLensing.ParamDependentOp"><code>CMBLensing.ParamDependentOp</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia">ParamDependentOp(recompute_function::Function)</code></pre><p>Creates an operator which depends on some parameters <span>$\theta$</span> and can be evaluated at various values of these parameters. </p><p><code>recompute_function</code> should be a function which accepts keyword arguments for <span>$\theta$</span> and returns the operator. Each keyword must have a default value; the operator will act as if evaluated at these defaults unless it is explicitly evaluated at other parameters. </p><p>Example:</p><pre class="language-julia"><code class="language-julia">Cϕ₀ = Diagonal(...) # some fixed Diagonal operator
Cϕ = ParamDependentOp((;Aϕ=1)-&gt;Aϕ*Cϕ₀) # create ParamDependentOp

Cϕ(Aϕ=1.1) * ϕ   # Cϕ(Aϕ=1.1) is equal to 1.1*Cϕ₀
Cϕ * ϕ           # Cϕ alone will act like Cϕ(Aϕ=1) because that was the default above</code></pre><p>Note: if you are doing parallel work, global variables referred to in the <code>recompute_function</code> need to be distributed to all workers. A more robust solution is to avoid globals entirely and instead ensure all variables are &quot;closed&quot; over (and hence will automatically get distributed). This will happen by default if defining the <code>ParamDependentOp</code> inside any function, or can be forced at the global scope by wrapping everything in a <code>let</code>-block, e.g.:</p><pre class="language-julia"><code class="language-julia">Cϕ = let Cϕ₀=Cϕ₀
    ParamDependentOp((;Aϕ=1)-&gt;Aϕ*Cϕ₀)
end</code></pre><p>After executing the code above, <code>Cϕ</code> is now ready to be (auto-)shipped to any workers and will work regardless of what global variables are defined on these workers. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.RK4Solver-Tuple{Function,Any,Any,Any,Any}" href="#CMBLensing.RK4Solver-Tuple{Function,Any,Any,Any,Any}"><code>CMBLensing.RK4Solver</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">RK4Solver(F!::Function, y₀, t₀, t₁, nsteps)</code></pre><p>Solve for <span>$y(t_1)$</span> with 4th order Runge-Kutta assuming <span>$dy/dt = F(t,y)$</span> and <span>$y(t_0)$</span> = <span>$y_0$</span>.</p><p>Arguments:</p><ul><li><code>F!</code> — a function <code>F!(v,t,y)</code><code>which sets</code>v=F(t,y)`</li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@ismain-Tuple{}" href="#CMBLensing.@ismain-Tuple{}"><code>CMBLensing.@ismain</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre class="language-julia"><code class="language-julia">@ismain()</code></pre><p>Return true if the current file is being run as a script.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@namedtuple-Tuple" href="#CMBLensing.@namedtuple-Tuple"><code>CMBLensing.@namedtuple</code></a> — <span class="docstring-category">Macro</span></header><section><div><p>Pack some variables into a NamedTuple. E.g.:</p><pre class="language-julia"><code class="language-julia">&gt; x = 3
&gt; y = 4
&gt; @namedtuple(x, y, z=5)
(x=3,y=4,z=5)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@repeated-Tuple{Any,Any}" href="#CMBLensing.@repeated-Tuple{Any,Any}"><code>CMBLensing.@repeated</code></a> — <span class="docstring-category">Macro</span></header><section><div><p>Return a tuple with the expression repeated n times </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@show⌛-Tuple{Any}" href="#CMBLensing.@show⌛-Tuple{Any}"><code>CMBLensing.@show⌛</code></a> — <span class="docstring-category">Macro</span></header><section><div><p>See <a href="#CMBLensing.@⌛-Tuple{Any}"><code>@⌛</code></a></p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@⌛-Tuple{Any}" href="#CMBLensing.@⌛-Tuple{Any}"><code>CMBLensing.@⌛</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre class="language-julia"><code class="language-julia">@⌛ code ...
@⌛ function_definition() = ....</code></pre><p>Label a section of code to be timed. The first form uses the code itselfs as a label, the second uses the function name, and its the body of the function which is timed. </p><p>To run the timer and print output, returning the result of the calculation, use</p><pre class="language-none"><code class="language-none">@show⌛ run_code()</code></pre><p>Timing uses <code>TimerOutputs.get_defaulttimer()</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.BinRescaledOp-Tuple{Any,Any,Symbol}" href="#CMBLensing.BinRescaledOp-Tuple{Any,Any,Symbol}"><code>CMBLensing.BinRescaledOp</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">BinRescaledOp(C₀, Cbins, θname::Symbol)</code></pre><p>Create a <a href="#CMBLensing.ParamDependentOp"><code>ParamDependentOp</code></a> which has a parameter named <code>θname</code> which is an array that controls the amplitude of bandpowers in bins given by <code>Cbins</code>. </p><p>For example, <code>BinRescaledOp(C₀, [Cbin1, Cbin2], :A)</code> creates the operator: </p><pre class="language-none"><code class="language-none">ParamDependentOp( (;A=[1,1], _...) -&gt; C₀ + (A[1]-1) * Cbin1 + (A[2]-1) * Cbin2 )</code></pre><p>where <code>C₀</code>, <code>Cbin1</code>, and <code>Cbin2</code> should be some <code>LinOp</code>s. Note <code>Cbins</code> are directly the power which is added, rather than a mask. </p><p>The resulting operator is differentiable in <code>θname</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.LinearInterpolation-Tuple{AbstractArray{T,1} where T,AbstractArray{T,1} where T}" href="#CMBLensing.LinearInterpolation-Tuple{AbstractArray{T,1} where T,AbstractArray{T,1} where T}"><code>CMBLensing.LinearInterpolation</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">itp = LinearInterpolation(xdat::AbstractVector, ydat::AbstractVector; extrapolation_bc=NaN)
itp(x) # interpolate at x</code></pre><p>A simple 1D linear interpolation code which is fully Zygote differentiable in either <code>xdat</code>, <code>ydat</code>, or the evaluation point <code>x</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.antilensing-Union{Tuple{PowerLens{N,F}}, Tuple{F}, Tuple{N}} where F where N" href="#CMBLensing.antilensing-Union{Tuple{PowerLens{N,F}}, Tuple{F}, Tuple{N}} where F where N"><code>CMBLensing.antilensing</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Create a PowerLens operator that lenses by -ϕ instead. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.batch_promote!-Tuple{Any,Any}" href="#CMBLensing.batch_promote!-Tuple{Any,Any}"><code>CMBLensing.batch_promote!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">batch_promote!(to, f)</code></pre><p>Promote <code>f</code> to the same batch size as <code>to</code> by replication. If both are already the same batch size, no copy is made and <code>f</code> is returned. If promotion needs to happen, the answer is stored in-place in <code>to</code> and returned. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.batchmap-Tuple{Any,Vararg{Any,N} where N}" href="#CMBLensing.batchmap-Tuple{Any,Vararg{Any,N} where N}"><code>CMBLensing.batchmap</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">batchmap(f, args...)</code></pre><p>map function <code>f</code> over <code>args</code>, unbatching them first if they are batched, and then batching the result.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.conjugate_gradient" href="#CMBLensing.conjugate_gradient"><code>CMBLensing.conjugate_gradient</code></a> — <span class="docstring-category">Function</span></header><section><div><pre class="language-julia"><code class="language-julia">conjugate_gradient(
    M, A, b, x=M\b; 
    nsteps       = length(b), 
    tol          = sqrt(eps()), 
    progress     = false, 
    callback     = nothing, 
    history_keys = nothing, 
    history_mod  = 1
)</code></pre><p>Compute <code>x=A\b</code> (where <code>A</code> is positive definite) by conjugate gradient. <code>M</code> is the preconditioner and should be <code>M≈A</code>, and <code>M\x</code> should be fast.</p><p>The solver will stop either after <code>nsteps</code> iterations or when <code>dot(r,r)&lt;tol</code> (where <code>r=A*x-b</code> is the residual  at that step), whichever occurs first.</p><p>Info from the iterations of the solver can be returned if <code>history_keys</code> is specified. <code>history_keys</code> can be one or a tuple of:</p><ul><li><code>:i</code> — current iteration number</li><li><code>:x</code> — current solution</li><li><code>:r</code> — current residual <code>r=A*x-b</code></li><li><code>:res</code> — the norm of <code>r</code></li><li><code>:t</code> — the time elapsed (in seconds) since the start of the algorithm</li></ul><p><code>history_mod</code> can be used to include every N-th iteration only in <code>history_keys</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.fftsyms-Union{Tuple{n}, Tuple{m}, Tuple{Val{m},Val{n}}} where n where m" href="#CMBLensing.fftsyms-Union{Tuple{n}, Tuple{m}, Tuple{Val{m},Val{n}}} where n where m"><code>CMBLensing.fftsyms</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Arguments <code>m</code> and <code>n</code> refer to the sizes of an <code>m</code>×<code>n</code> matrix (call it <code>A</code>) that is the output of a real FFT (thus <code>m=n÷2+1</code>)</p><p>Returns a tuple of (ireal, iimag, negks) where these are</p><ul><li><code>ireal</code> — <code>m</code>×<code>n</code> mask corrsponding to unique real entries of <code>A</code></li><li><code>iimag</code> — <code>m</code>×<code>n</code> mask corrsponding to unique imaginary entries of <code>A</code></li><li><code>negks</code> — <code>m</code>×<code>n</code> matrix of giving the index into A where the negative k-vector           is, s.t. <code>A[i,j] = A[negks[i,j]]&#39;</code></li></ul></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.fieldvalues-Tuple{Any}" href="#CMBLensing.fieldvalues-Tuple{Any}"><code>CMBLensing.fieldvalues</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Return the type&#39;s fields as a tuple</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.finite_second_derivative-Tuple{Any}" href="#CMBLensing.finite_second_derivative-Tuple{Any}"><code>CMBLensing.finite_second_derivative</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">finite_second_derivative(x)</code></pre><p>Second derivative of a vector <code>x</code> via finite differences, including at end points.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.get_term_memoizer-Tuple{Any}" href="#CMBLensing.get_term_memoizer-Tuple{Any}"><code>CMBLensing.get_term_memoizer</code></a> — <span class="docstring-category">Method</span></header><section><div><p>All of the terms in the quadratic estimate and normalization expressions look like</p><pre class="language-none"><code class="language-none">C * l[i] * l̂[j] * l̂[k] * ...</code></pre><p>where C is some field or diagonal covariance. For example, there&#39;s a term in the EB estimator that looks like:</p><pre class="language-none"><code class="language-none">(CE * (CẼ+Cn) \ d[:E])) * l[i] * l̂[j] * l̂[k]</code></pre><p>(where note that <code>l̂[j]</code> and <code>l̂[k]</code> are unit vectors, but <code>l[i]</code> is not).  The function <code>get_term_memoizer</code> returns a function <code>term</code> which could be called in the following way to compute this term:</p><pre class="language-none"><code class="language-none">term((CE * (CẼ+Cn) \ d[:E])), [i], j, k)</code></pre><p>(note that the fact that <code>l[i]</code> is not a unit vector is specified by putting the <code>[i]</code> index in brackets). </p><p>Additionally, all of these terms are symmetric in their indices, i.e. in <code>(i,j,k)</code> in this case. The <code>term</code> function is smart about this, and is memoized so that each unique set of indices is only computed once. This leads to a pretty drastic speedup for terms with many indices like those that arize in the EE and EB normalizations, and lets us write code which is both clear and fast without having to think too hard about these symmetries.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.gmres-Tuple{Any,Any}" href="#CMBLensing.gmres-Tuple{Any,Any}"><code>CMBLensing.gmres</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">gmres(A, b; maxiter, Pl=I)</code></pre><p>Solve <code>A \ b</code> with <code>maxiter</code> iterations of the <a href="https://en.wikipedia.org/wiki/Generalized_minimal_residual_method">generalized minimal residual</a> algorithm. <code>Pl</code> is a left-preconditioner which should approximate <code>inv(A)</code>. </p><p>Note: the implemenation is memory inefficient and uses O(n * maxiter) memory, where <code>n,n=size(A)</code> (may not be a big deal for small <code>maxiter</code>), although is totally generic and works with CPU or GPU and dense or sparse matrices, unlike IterativeSolver&#39;s <code>gmres</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.grid_and_sample-Tuple{Function,AbstractArray{T,1} where T}" href="#CMBLensing.grid_and_sample-Tuple{Function,AbstractArray{T,1} where T}"><code>CMBLensing.grid_and_sample</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">grid_and_sample(lnP::Function; range::NamedTuple; progress=false, nsamples=1)</code></pre><p>Interpolate the log pdf <code>lnP</code> with support on <code>range</code>, and return  the integrated log pdf as well <code>nsamples</code> samples (drawn via inverse transform sampling)</p><p><code>lnP</code> should either accept a NamedTuple argument and <code>range</code> should be a NamedTuple mapping those same names to <code>range</code> objects specifying where to evaluate <code>lnP</code>, e.g.:</p><pre class="language-julia"><code class="language-julia">grid_and_sample(nt-&gt;-(nt.x^2+nt.y^2)/2, (x=range(-3,3,length=100),y=range(-3,3,length=100)))</code></pre><p>or <code>lnP</code> should accept a single scalar argument and <code>range</code> should be directly the range for this variable:</p><pre class="language-julia"><code class="language-julia">grid_and_sample(x-&gt;-x^2/2, range(-3,3,length=100))</code></pre><p>The return value is <code>(lnP, samples, Px)</code> where <code>lnP</code> is an interpolated/smoothed log PDF which can be evaluated anywhere within the original range, <code>Px</code> are sampled points of the original PDF, and <code>samples</code> is a NamedTuple giving the Monte-Carlo samples of each of the parameters.</p><p>(Note: only 1D sampling is currently implemented, but 2D like in the example above is planned)</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.longest_run_of_trues-Tuple{Any}" href="#CMBLensing.longest_run_of_trues-Tuple{Any}"><code>CMBLensing.longest_run_of_trues</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">longest_run_of_trues(x)</code></pre><p>The slice corresponding to the longest run of <code>true</code>s in the vector <code>x</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.paren_errors-Tuple{Any,Any}" href="#CMBLensing.paren_errors-Tuple{Any,Any}"><code>CMBLensing.paren_errors</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">paren_errors(μ, σ; N_in_paren=2)</code></pre><p>Get a string represntation of <code>μ ± σ</code> in &quot;parenthesis&quot; format, e.g. <code>1.234 ± 0.012</code> becomes <code>1.234(12)</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.rfft2vec-Tuple{AbstractArray{T,2} where T}" href="#CMBLensing.rfft2vec-Tuple{AbstractArray{T,2} where T}"><code>CMBLensing.rfft2vec</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Convert a matrix A which is the output of a real FFT to a real vector, keeping only unqiue real/imaginary entries of A</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.safe_pyimport-Tuple{Any}" href="#CMBLensing.safe_pyimport-Tuple{Any}"><code>CMBLensing.safe_pyimport</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">safe_pyimport(s)</code></pre><p>Like <code>pyimport</code>, but if <code>s</code> fails to import, instead of an error right away, the error will be thrown the first time the user tries to access the contents of the module.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.unfold-Tuple{AbstractArray{var&quot;#s25&quot;,3} where var&quot;#s25&quot;&lt;:Complex,Any}" href="#CMBLensing.unfold-Tuple{AbstractArray{var&quot;#s25&quot;,3} where var&quot;#s25&quot;&lt;:Complex,Any}"><code>CMBLensing.unfold</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Convert an M×N matrix (with M=N÷2+1) which is the output a real FFT to a full N×N one via symmetries.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.vec2rfft-Tuple{AbstractArray{var&quot;#s13&quot;,1} where var&quot;#s13&quot;&lt;:Real}" href="#CMBLensing.vec2rfft-Tuple{AbstractArray{var&quot;#s13&quot;,1} where var&quot;#s13&quot;&lt;:Real}"><code>CMBLensing.vec2rfft</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Convert a vector produced by rfft2vec back into a complex matrix.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.Σ-Tuple{Field,Any}" href="#CMBLensing.Σ-Tuple{Field,Any}"><code>CMBLensing.Σ</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">Σ(ϕ::Field,  ds; [conjgrad_kwargs])
Σ(Lϕ,        ds; [conjgrad_kwargs])</code></pre><p>An operator for the data covariance, Cn + P<em>M</em>B<em>L</em>Cf<em>L&#39;</em>B&#39;<em>M&#39;</em>P&#39;, which can applied and inverted. <code>conjgrad_kwargs</code> are passed to the underlying call to <code>conjugate_gradient</code>.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="LinearAlgebra.logdet-Tuple{Union{CMBLensing.ImplicitOp{B,S,P}, Diagonal{T,var&quot;#s103&quot;} where T where var&quot;#s103&quot;&lt;:(Field{B,S,P,T} where T)} where P where S where B,Any}" href="#LinearAlgebra.logdet-Tuple{Union{CMBLensing.ImplicitOp{B,S,P}, Diagonal{T,var&quot;#s103&quot;} where T where var&quot;#s103&quot;&lt;:(Field{B,S,P,T} where T)} where P where S where B,Any}"><code>LinearAlgebra.logdet</code></a> — <span class="docstring-category">Method</span></header><section><div><pre class="language-julia"><code class="language-julia">logdet(L::LinOp, θ)</code></pre><p>If L depends on θ, evaluates <code>logdet(L(θ))</code> offset by its fiducial value at <code>L()</code>. Otherwise, returns 0.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.BatchedReal" href="#CMBLensing.BatchedReal"><code>CMBLensing.BatchedReal</code></a> — <span class="docstring-category">Type</span></header><section><div><pre class="language-julia"><code class="language-julia">BatchedReal(::Vector{&lt;:Real}) &lt;: Real</code></pre><p>Holds a vector of real numbers and broadcasts algebraic operations over them, as well as broadcasting with batched <code>FlatField</code>s, but is itself a <code>Real</code>. </p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@!-Tuple{Any}" href="#CMBLensing.@!-Tuple{Any}"><code>CMBLensing.@!</code></a> — <span class="docstring-category">Macro</span></header><section><div><p>Rewrites <code>@! x = f(args...)</code> to <code>x = f!(x,args...)</code></p><p>Special cases for <code>*</code> and <code>\</code> forward to <code>mul!</code> and <code>ldiv!</code>, respectively.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@dict-Tuple" href="#CMBLensing.@dict-Tuple"><code>CMBLensing.@dict</code></a> — <span class="docstring-category">Macro</span></header><section><div><p>Pack some variables in a dictionary </p><pre class="language-julia"><code class="language-julia">&gt; x = 3
&gt; y = 4
&gt; @dict x y z=&gt;5
Dict(:x=&gt;3,:y=&gt;4,:z=&gt;5)</code></pre></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@ondemand-Tuple{Any}" href="#CMBLensing.@ondemand-Tuple{Any}"><code>CMBLensing.@ondemand</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre class="language-julia"><code class="language-julia">@ondemand(Package.function)(args...; kwargs...)
@ondemand(Package.Submodule.function)(args...; kwargs...)</code></pre><p>Just like calling <code>Package.function</code> or <code>Package.Submodule.function</code>, but <code>Package</code> will be loaded on-demand if it is not already loaded. The call is no longer inferrable.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@subst-Tuple{Any}" href="#CMBLensing.@subst-Tuple{Any}"><code>CMBLensing.@subst</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre class="language-julia"><code class="language-julia">@subst sum(x*$(y+1) for x=1:2)</code></pre><p>becomes</p><pre class="language-none"><code class="language-none">let tmp=(y+1)
    sum(x*tmp for x=1:2)
end</code></pre><p>to aid in writing clear/succinct code that doesn&#39;t recompute things unnecessarily.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.@sym_memo-Tuple{Any}" href="#CMBLensing.@sym_memo-Tuple{Any}"><code>CMBLensing.@sym_memo</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre class="language-julia"><code class="language-julia"># symmetric in any of its final arguments except for bar:
@sym_memo foo(bar, @sym(args...)) = &lt;body&gt; 
# symmetric in (i,j), but not baz
@sym_memo foo(baz, @sym(i, j)) = &lt;body&gt;</code></pre><p>The <code>@sym_memo</code> macro should be applied to a definition of a function which is symmetric in some of its arguments. The arguments in which its symmetric are specified by being wrapping them in @sym, and they must come at the very end. The resulting function will be memoized and permutations of the arguments which are equal due to symmetry will only be computed once.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FFTW_NUM_THREADS" href="#CMBLensing.FFTW_NUM_THREADS"><code>CMBLensing.FFTW_NUM_THREADS</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>The number of threads used by FFTW for CPU FFTs (default is the environment variable <code>FFTW_NUM_THREADS</code>, or if that is not specified its <code>Sys.CPU_THREADS÷2</code>). This must be set before creating any <code>FlatField</code> objects.</p></div></section></article><article class="docstring"><header><a class="docstring-binding" id="CMBLensing.FFTW_TIMELIMIT" href="#CMBLensing.FFTW_TIMELIMIT"><code>CMBLensing.FFTW_TIMELIMIT</code></a> — <span class="docstring-category">Constant</span></header><section><div><p>Time-limit for FFT planning on CPU (default: 5 seconds). This must be set before creating any <code>FlatField</code> objects.</p></div></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../06_gpu/">« GPU</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 22 December 2020 01:24">Tuesday 22 December 2020</span>. Using Julia version 1.5.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
